<img width="1916" height="862" alt="image" src="https://github.com/user-attachments/assets/a339b37f-32ef-460f-9351-be39bd5b86a0" />

ğŸ§  Project Overview
This application is a Medical Domain Chatbot built using Retrieval-Augmented Generation (RAG). It allows users to upload their own medical documents (e.g., textbooks, reports), and the system intelligently answers queries by retrieving the most relevant content before generating a final response.

ğŸ“ What is RAG?
RAG (Retrieval-Augmented Generation) enhances language models by supplying relevant external context from a knowledge base, preventing hallucinations and improving accuracy, especially for factual or specialized domains like medicine.

ğŸ”„ Architecture
User Input
   â†“
Query Embedding â†’ Pinecone Vector DB â† Embedded Chunks â† Chunking â† PDF Loader
   â†“
Retrieved Docs
   â†“
     RAG Chain (Groq + LangChain)
   â†“
LLM-generated Answer

ğŸ“š Features
Upload medical PDFs (notes, books, etc.)
Auto-extracts text and splits into semantic chunks
Embeds using Google/BGE embeddings
Stores vectors in Pinecone DB
Uses Groq's LLaMA3-70B via LangChain
FastAPI backend with endpoints for file upload and Q&A

ğŸŒ Tech Stack
Component	    Tech Used

LLM	          Groq API (LLaMA3-70B)
Embeddings  	Google Generative AI / BGE
Vector DB    	Pinecone
Framework     LangChain
Backend	      FastAPI
Deployment	  Render


